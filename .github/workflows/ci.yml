name: CI

on:
  push:
    branches-ignore:
      - 'compare-baseline-*'
  pull_request:

env:
  PYTHONUNBUFFERED: '1'
  CCACHE_BASEDIR: ${{ github.workspace }}
  CCACHE_DIR: ${{ github.workspace }}/.ccache
  CCACHE_MAXSIZE: 400M
  CCACHE_SLOPPINESS: time_macros

jobs:
  # Get the LFS cache ready. This avoids every shard of each environment downloads the LFS objects
  # at the same time whenever any change, which is disastrous for quota.
  warm-lfs-cache:
    runs-on: ubuntu-latest
    steps:
      - name: git clone
        uses: nschloe/action-cached-lfs-checkout@d6efedcb8fc03d006e1e77743718e26234ed2c97

  test:
    needs: warm-lfs-cache
    strategy:
      matrix:
        include:
          - runs-on: windows-2022
            arch: x64
            compiler: msvc
            config: RelWithDebInfo
          - runs-on: windows-2022
            arch: win32
            compiler: msvc
            # RelWithDebInfo fails all replays on 32 bit
            config: Release
            extra-args: --max_duration 60
          - runs-on: macos-12
            arch: intel
            compiler: clang
            config: RelWithDebInfo
          - runs-on: ubuntu-22.04
            arch: x64
            compiler: clang
            config: RelWithDebInfo
      fail-fast: false
    # See https://github.com/community/community/discussions/40777
    # uses: ./.github/workflows/test.yml
    uses: ArmageddonGames/ZQuestClassic/.github/workflows/test.yml@main
    with:
      runs-on: ${{ matrix.runs-on }}
      arch: ${{ matrix.arch }}
      compiler: ${{ matrix.compiler }}
      config: ${{ matrix.config }}
      extra-args: ${{ matrix.extra-args }}

  compare:
    needs: ["test"]
    runs-on: ubuntu-latest
    if: failure()
    env:
      REPLAY_FAILURE_DISCORD_WEBHOOK: ${{ secrets.REPLAY_FAILURE_DISCORD_WEBHOOK }}

    steps:
      - uses: actions/setup-python@v4
        with:
          python-version: '3.10' 
      - run: pip install PyGithub==1.58.2 requests discord.py watchdog Pillow intervaltree cutie
      - name: Install Node.js 18.x
        uses: actions/setup-node@v3
        with:
          node-version: 18.x
      - name: git clone
        uses: actions/checkout@v3

      # TODO: there is no simple way to download just the "replay-*" artifacts,
      # so currently this also downloads each large build artifact.
      # https://github.com/actions/download-artifact/issues/6
      - uses: actions/download-artifact@v3
        with:
          path: test-results

      # TODO: instead of starting baseline workflow runs when all platforms finish,
      # kick each off as necessary in `test.yml` and just poll for their completion here.
      - name: Collect baseline
        run: python3 tests/run_test_workflow.py --test_results test-results --repo ${{ github.repository }} --token ${{ secrets.GITHUB_TOKEN }}
        id: collect-baseline
      - name: Generate report
        run: python3 tests/compare_replays.py --workflow_run ${{ steps.collect-baseline.outputs.baseline_run_id }} --local test-results --repo ${{ github.repository }} --token ${{ secrets.GITHUB_TOKEN }}

      - run: npx surge ${{ github.workspace }}/tests/compare-report zc-replay-compare-${{ github.run_id }}.surge.sh --token ${{ secrets.SURGE_TOKEN }}
        name: Upload to https://zc-replay-compare-${{ github.run_id }}.surge.sh

      - name: Discord notification
        shell: python
        run: |
          import inspect
          import discord

          url = '${{ secrets.REPLAY_FAILURE_DISCORD_WEBHOOK }}'
          ref_name = '${{ github.ref_name }}'
          run_id = '${{ github.run_id }}'
          repository = '${{ github.repository }}'
          actor = '${{ github.actor }}'

          content = inspect.cleandoc(f'''
              Report: https://zc-replay-compare-{run_id}.surge.sh
              CI: https://github.com/{repository}/actions/runs/{run_id}
              Actor: {actor}
          ''')

          webhook = discord.SyncWebhook.from_url(url)
          webhook.send(
              content,
              thread_name=f'Replay tests failed for {ref_name}',
              wait=True,
          )

      # Upload as artifact, so that if publishing to surge fails the report is still accessible.
      - uses: actions/upload-artifact@v3
        if: always()
        with:
          name: report
          path: ${{ github.workspace }}/tests/compare-report

  web:
    needs: warm-lfs-cache
    runs-on: ubuntu-22.04

    steps:
      - name: git clone
        uses: nschloe/action-cached-lfs-checkout@d6efedcb8fc03d006e1e77743718e26234ed2c97

      - uses: mymindstorm/setup-emsdk@v12
        with:
          version: "3.1.32"
          actions-cache-folder: "emsdk-cache-${{ runner.os }}-${{ runner.arch }}"

      - name: Install Node.js 18.x
        uses: actions/setup-node@v3
        with:
          node-version: 18.x
      # puppeteer caches Chrome in ~/.ccache/puppeteer, but only on npm install. Which means
      # restored caches from actions/setup-node will never install Chrome.
      - run: npm rm puppeteer && npm add puppeteer@20.5.0

      - run: sudo apt-get update && sudo apt-get install ccache ninja-build flex bison

      # Setup build cache via ccache.
      - name: ccache cache files
        uses: actions/cache@v3
        with:
          path: .ccache
          key: web-ccache-${{ github.run_id }}
          restore-keys: web-ccache-
      - run: ccache -z

      - run: |
          git clone https://github.com/psi29a/unsf.git
          cd unsf
          cmake -S . -B build .
          cmake --build build
          echo "UNSF=$PWD/build/unsf-static" >> $GITHUB_ENV

      - run: cp src/metadata/*.h.sig src/metadata/sigs/
      - run: |
          git config --global user.email "you@example.com"
          git config --global user.name "Your Name"
      - run: bash scripts/build_emscripten.sh
        env:
          ZC_EMCC_CMAKE_EXTRA_FLAGS: -DCMAKE_C_COMPILER_LAUNCHER=ccache -DCMAKE_CXX_COMPILER_LAUNCHER=ccache
          ZC_PACKAGE_REPLAYS: 1
      - run: ccache -s

      - run: sudo apt-get update && sudo apt-get install libopengl0 libglu1
      - run: sudo apt-get install xvfb
      - run: npm install
        working-directory: web
      - run: xvfb-run --auto-servernum npm run test -- --timeout 100000 || xvfb-run --auto-servernum npm run test -- --timeout 100000 || xvfb-run --auto-servernum npm run test -- --timeout 100000
        working-directory: web
      - run: pip install PyGithub==1.58.2 requests discord.py watchdog Pillow intervaltree cutie
      # Run each replay for just ~15 seconds, but run all of classic_1st_lvl1.zplay
      - run: xvfb-run --auto-servernum python -Xutf8 tests/run_replay_tests.py --build_folder build_emscripten/Release --max_duration 15 --max_duration classic_1st_lvl1.zplay=0 --test_results .tmp/test_results --ci web --retries 2

      - uses: actions/upload-artifact@v3
        if: failure()
        with:
          name: emscripten cmake
          path: |
            ${{ github.workspace }}/build_emscripten/CMakeFiles/CMakeOutput.log
            ${{ github.workspace }}/build_emscripten/CMakeFiles/CMakeError.log
            ${{ github.workspace }}/.tmp/test_results
